conditions:
  - name: rank_vicuna_7b_v1_splade_pp
    display: "RankVicuna 7B V1"
    display-html: "RankVicuna 7B V1"
    display-row: "[1]"
    command: python src/rank_llm/scripts/run_rank_llm.py --model_path=castorini/rank_vicuna_7b_v1  --top_k_candidates=100 --dataset=$topics  --retrieval_method=SPLADE++_EnsembleDistil_ONNX --prompt_mode=rank_GPT  --context_size=4096
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7360
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.7358
  - name: rank_zephyr_7b_v1_full_splade_pp
    display: "RankZephyr 7B V1 - Full"
    display-html: "RankZephyr 7B V1 - Full"
    display-row: "[2]"
    command: python src/rank_llm/scripts/run_rank_llm.py --model_path=castorini/rank_zephyr_7b_v1_full  --top_k_candidates=100 --dataset=$topics  --retrieval_method=SPLADE++_EnsembleDistil_ONNX --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7803
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.8211
  - name: rank_zephyr_7b_v1_full_splade_pp_mult_pass
    display: "RankZephyr 7B V1 - Full"
    display-html: "RankZephyr 7B V1 - Full"
    display-row: "[2]"
    command: python src/rank_llm/scripts/run_rank_llm.py --model_path=castorini/rank_zephyr_7b_v1_full  --top_k_candidates=100 --dataset=$topics  --retrieval_method=SPLADE++_EnsembleDistil_ONNX --prompt_mode=rank_GPT  --context_size=4096 --variable_passages --num_passes=3
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - MULT: 3
          - nDCG@10: 0.7855
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - MULT: 3
          - nDCG@10: 0.8255
  - name: monot5
    display: "Monot5 3B MSMARCO-10k"
    display-html: "Monot5 3B MSMARCO-10k"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/monot5-3b-msmarco-10k --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7174
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6878
  - name: duot5
    display: "Duot5 3B MSMARCO-10k"
    display-html: "Duot5 3B MSMARCO-10k"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/duot5-3b-msmarco-10k --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7302
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6913
  - name: lit5distill
    display: "Lit5Distill Large"
    display-html: "Lit5Distill Large"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/LiT5-Distill-large --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7247
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.7049
  - name: rank_vicuna_7b_v1_bm25
    display: "RankVicuna 7B V1"
    display-html: "RankVicuna 7B V1"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/rank_vicuna_7b_v1 --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.6874
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6630
  - name: rank_zephyr_7b_v1_full_bm25
    display: "RankZephyr 7B V1 - Full"
    display-html: "RankZephyr 7B V1 - Full"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/rank_zephyr_7b_v1_full --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7388
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.7106
  - name: firstmistral
    display: "First Mistral"
    display-html: "First Mistral"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=castorini/first_mistral --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages --use_alpha --use_logits
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7245
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.7074
  - name: qwen_2.5_7b_inst
    display: "Qwen 2.5 7B Instruct"
    display-html: "Qwen 2.5 7B Instruct"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=Qwen/Qwen2.5-7B-Instruct --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.6930
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6368
  - name: llama_3.1_8b_inst
    display: "LLaMA 3.1 8B Instruct"
    display-html: "LLaMA 3.1 8B Instruct"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=meta-llama/Llama-3.1-8B-Instruct --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.6718
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6342
  - name: gemini_flash_2.0
    display: "Gemini 2.0 Flash"
    display-html: "Gemini 2.0 Flash"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=gemini-2.0-flash --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT  --context_size=4096 --variable_passages
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7362
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6930
  - name: rankgpt
    display: "RankGPT (gpt-4o-mini)"
    display-html: "RankGPT (gpt-4o-mini)"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=gpt-4o-mini --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT --context_size=4096 --variable_passages --use_azure_openai
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7306
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6781
  - name: rankgptapeer
    display: "RankGPTAPEER (gpt-4o-mini)"
    display-html: "RankGPTAPEER (gpt-4o-mini)"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=gpt-4o-mini --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=rank_GPT_APEER --context_size=4096 --variable_passages --use_azure_openai
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7278
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6912
  - name: lrl
    display: "LRL (gpt-4o-mini)"
    display-html: "LRL (gpt-4o-mini)"
    display-row: "[4]"
    command: python src/rank_llm/scripts/run_rank_llm.py  --model_path=gpt-4o-mini --top_k_candidates=100 --dataset=$topics --retrieval_method=bm25 --prompt_mode=LRL --context_size=4096 --variable_passages --use_azure_openai
    topics:
      - topic_key: dl19
        eval_key: dl19-passage
        scores:
          - nDCG@10: 0.7149
      - topic_key: dl20
        eval_key: dl20-passage
        scores:
          - nDCG@10: 0.6722
